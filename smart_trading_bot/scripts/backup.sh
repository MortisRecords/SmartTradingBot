#!/bin/bash

# Smart Trading Bot - Backup Script
# –°–∫—Ä–∏–ø—Ç —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π

set -e  # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å—Å—è –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö

# –¶–≤–µ—Ç–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
log_info() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')] [INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] [SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] [WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[$(date +'%Y-%m-%d %H:%M:%S')] [ERROR]${NC} $1"
}

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
PROJECT_DIR="/opt/smart_trading_bot"
BACKUP_DIR="/opt/backups/smart_trading_bot"
MAX_BACKUPS=30  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±—ç–∫–∞–ø–æ–≤
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_NAME="backup_${TIMESTAMP}"
CURRENT_BACKUP_DIR="${BACKUP_DIR}/${BACKUP_NAME}"

# AWS S3 –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
S3_BUCKET="${S3_BACKUP_BUCKET:-}"
AWS_REGION="${AWS_REGION:-us-east-1}"

# Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
TELEGRAM_BOT_TOKEN="${BACKUP_NOTIFICATION_BOT_TOKEN:-}"
TELEGRAM_CHAT_ID="${BACKUP_NOTIFICATION_CHAT_ID:-}"

# –§—É–Ω–∫—Ü–∏—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤ Telegram
send_telegram_notification() {
    local message="$1"
    
    if [[ -n "$TELEGRAM_BOT_TOKEN" && -n "$TELEGRAM_CHAT_ID" ]]; then
        curl -s -X POST "https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}/sendMessage" \
            -d "chat_id=${TELEGRAM_CHAT_ID}" \
            -d "text=${message}" \
            -d "parse_mode=HTML" > /dev/null 2>&1 || true
    fi
}

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
check_dependencies() {
    log_info "–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π..."
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ Docker
    if ! command -v docker &> /dev/null; then
        log_error "Docker –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"
        exit 1
    fi
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ docker-compose
    if ! command -v docker-compose &> /dev/null; then
        log_error "docker-compose –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"
        exit 1
    fi
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞
    if [[ ! -d "$PROJECT_DIR" ]]; then
        log_error "–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: $PROJECT_DIR"
        exit 1
    fi
    
    log_success "–í—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≤ –ø–æ—Ä—è–¥–∫–µ"
}

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è –±—ç–∫–∞–ø–∞
create_backup_directories() {
    log_info "–°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è –±—ç–∫–∞–ø–∞..."
    
    mkdir -p "$BACKUP_DIR"
    mkdir -p "$CURRENT_BACKUP_DIR"
    mkdir -p "$CURRENT_BACKUP_DIR/database"
    mkdir -p "$CURRENT_BACKUP_DIR/files"
    mkdir -p "$CURRENT_BACKUP_DIR/logs"
    mkdir -p "$CURRENT_BACKUP_DIR/config"
    
    log_success "–î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å–æ–∑–¥–∞–Ω—ã"
}

# –ë—ç–∫–∞–ø –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
backup_database() {
    log_info "–°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö..."
    
    cd "$PROJECT_DIR"
    
    # PostgreSQL –±—ç–∫–∞–ø
    if docker-compose ps postgres | grep -q "Up"; then
        log_info "–°–æ–∑–¥–∞–Ω–∏–µ PostgreSQL –¥–∞–º–ø–∞..."
        
        # –ü–æ–ª–Ω—ã–π –¥–∞–º–ø
        docker-compose exec -T postgres pg_dump -U postgres -d trading_bot \
            > "$CURRENT_BACKUP_DIR/database/postgresql_full.sql"
        
        # –î–∞–º–ø —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã—Ö
        docker-compose exec -T postgres pg_dump -U postgres -d trading_bot --data-only \
            > "$CURRENT_BACKUP_DIR/database/postgresql_data.sql"
        
        # –î–∞–º–ø —Ç–æ–ª—å–∫–æ —Å—Ö–µ–º—ã
        docker-compose exec -T postgres pg_dump -U postgres -d trading_bot --schema-only \
            > "$CURRENT_BACKUP_DIR/database/postgresql_schema.sql"
        
        # –°–∂–∞—Ç–∏–µ –¥–∞–º–ø–æ–≤
        gzip "$CURRENT_BACKUP_DIR/database/postgresql_full.sql"
        gzip "$CURRENT_BACKUP_DIR/database/postgresql_data.sql"
        gzip "$CURRENT_BACKUP_DIR/database/postgresql_schema.sql"
        
        log_success "PostgreSQL –¥–∞–º–ø —Å–æ–∑–¥–∞–Ω"
    else
        log_warning "PostgreSQL –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –Ω–µ –∑–∞–ø—É—â–µ–Ω"
    fi
    
    # Redis –±—ç–∫–∞–ø
    if docker-compose ps redis | grep -q "Up"; then
        log_info "–°–æ–∑–¥–∞–Ω–∏–µ Redis –¥–∞–º–ø–∞..."
        
        docker-compose exec -T redis redis-cli --rdb - > "$CURRENT_BACKUP_DIR/database/redis_dump.rdb"
        gzip "$CURRENT_BACKUP_DIR/database/redis_dump.rdb"
        
        log_success "Redis –¥–∞–º–ø —Å–æ–∑–¥–∞–Ω"
    else
        log_warning "Redis –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –Ω–µ –∑–∞–ø—É—â–µ–Ω"
    fi
}

# –ë—ç–∫–∞–ø —Ñ–∞–π–ª–æ–≤
backup_files() {
    log_info "–°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ —Ñ–∞–π–ª–æ–≤..."
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    cp "$PROJECT_DIR/.env" "$CURRENT_BACKUP_DIR/config/" 2>/dev/null || log_warning ".env —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω"
    cp "$PROJECT_DIR/docker-compose.yml" "$CURRENT_BACKUP_DIR/config/"
    cp "$PROJECT_DIR/requirements.txt" "$CURRENT_BACKUP_DIR/config/"
    
    # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
    if [[ -d "$PROJECT_DIR/data" ]]; then
        cp -r "$PROJECT_DIR/data" "$CURRENT_BACKUP_DIR/files/"
        log_info "–î–∞–Ω–Ω—ã–µ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω—ã"
    fi
    
    # –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    if [[ -d "$PROJECT_DIR/uploads" ]]; then
        cp -r "$PROJECT_DIR/uploads" "$CURRENT_BACKUP_DIR/files/"
        log_info "–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω—ã"
    fi
    
    # SSL —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã
    if [[ -d "/etc/letsencrypt" ]]; then
        mkdir -p "$CURRENT_BACKUP_DIR/files/ssl"
        cp -r /etc/letsencrypt "$CURRENT_BACKUP_DIR/files/ssl/" 2>/dev/null || true
        log_info "SSL —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω—ã"
    fi
    
    log_success "–§–∞–π–ª—ã —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω—ã"
}

# –ë—ç–∫–∞–ø –ª–æ–≥–æ–≤
backup_logs() {
    log_info "–°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ –ª–æ–≥–æ–≤..."
    
    # –õ–æ–≥–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    if [[ -d "$PROJECT_DIR/logs" ]]; then
        cp -r "$PROJECT_DIR/logs" "$CURRENT_BACKUP_DIR/"
        
        # –°–∂–∏–º–∞–µ–º –±–æ–ª—å—à–∏–µ –ª–æ–≥-—Ñ–∞–π–ª—ã
        find "$CURRENT_BACKUP_DIR/logs" -name "*.log" -size +10M -exec gzip {} \;
        
        log_info "–õ–æ–≥–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω—ã"
    fi
    
    # –õ–æ–≥–∏ —Å–∏—Å—Ç–µ–º—ã
    mkdir -p "$CURRENT_BACKUP_DIR/logs/system"
    
    # –õ–æ–≥–∏ Docker
    if [[ -d "/var/lib/docker/containers" ]]; then
        cd "$PROJECT_DIR"
        for container in $(docker-compose ps -q); do
            container_name=$(docker inspect --format='{{.Name}}' "$container" | sed 's/\///')
            docker logs "$container" > "$CURRENT_BACKUP_DIR/logs/system/${container_name}.log" 2>&1 || true
        done
        log_info "–õ–æ–≥–∏ Docker —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω—ã"
    fi
    
    # –õ–æ–≥–∏ Nginx
    if [[ -d "/var/log/nginx" ]]; then
        cp /var/log/nginx/*smart* "$CURRENT_BACKUP_DIR/logs/system/" 2>/dev/null || true
        log_info "–õ–æ–≥–∏ Nginx —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω—ã"
    fi
    
    log_success "–õ–æ–≥–∏ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω—ã"
}

# –°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –±—ç–∫–∞–ø–∞
create_backup_metadata() {
    log_info "–°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –±—ç–∫–∞–ø–∞..."
    
    cat > "$CURRENT_BACKUP_DIR/backup_info.json" << EOF
{
    "backup_name": "$BACKUP_NAME",
    "timestamp": "$TIMESTAMP",
    "date": "$(date -Iseconds)",
    "hostname": "$(hostname)",
    "project_dir": "$PROJECT_DIR",
    "backup_type": "full",
    "components": {
        "database": true,
        "files": true,
        "logs": true,
        "config": true
    },
    "database_info": {
        "postgresql": {
            "version": "$(docker-compose -f $PROJECT_DIR/docker-compose.yml exec -T postgres psql -U postgres -t -c 'SELECT version();' 2>/dev/null | head -1 | xargs || echo 'N/A')"
        },
        "redis": {
            "version": "$(docker-compose -f $PROJECT_DIR/docker-compose.yml exec -T redis redis-server --version 2>/dev/null | cut -d' ' -f3 || echo 'N/A')"
        }
    },
    "system_info": {
        "os": "$(uname -a)",
        "docker_version": "$(docker --version)",
        "docker_compose_version": "$(docker-compose --version)",
        "disk_usage": "$(df -h $BACKUP_DIR | tail -1)"
    }
}
EOF
    
    # –°–æ–∑–¥–∞–Ω–∏–µ README
    cat > "$CURRENT_BACKUP_DIR/README.md" << EOF
# Smart Trading Bot Backup

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** $(date)
**–ò–º—è –±—ç–∫–∞–ø–∞:** $BACKUP_NAME

## –°–æ–¥–µ—Ä–∂–∏–º–æ–µ

- \`database/\` - –î–∞–º–ø—ã PostgreSQL –∏ Redis
- \`files/\` - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
- \`config/\` - –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (.env, docker-compose.yml)
- \`logs/\` - –õ–æ–≥–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∏ —Å–∏—Å—Ç–µ–º—ã
- \`backup_info.json\` - –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –±—ç–∫–∞–ø–∞

## –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ

### –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö PostgreSQL:
\`\`\`bash
# –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã
docker-compose down

# –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–æ–ª—å–∫–æ PostgreSQL
docker-compose up -d postgres

# –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –¥–∞–º–ø
gunzip -c database/postgresql_full.sql.gz | docker-compose exec -T postgres psql -U postgres -d trading_bot
\`\`\`

### –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö Redis:
\`\`\`bash
# –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Redis
docker-compose stop redis

# –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –¥–∞–º–ø
gunzip -c database/redis_dump.rdb.gz > /var/lib/docker/volumes/redis_data/_data/dump.rdb

# –ó–∞–ø—É—Å—Ç–∏—Ç—å Redis
docker-compose start redis
\`\`\`

### –§–∞–π–ª—ã:
\`\`\`bash
# –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
cp -r files/data/* /opt/smart_trading_bot/data/

# –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
cp config/.env /opt/smart_trading_bot/
\`\`\`

## –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–∑–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤ –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ö—ç—à–µ–π –≤ backup_info.json
EOF

    # –†–∞—Å—á–µ—Ç —Ä–∞–∑–º–µ—Ä–∞ –±—ç–∫–∞–ø–∞
    BACKUP_SIZE=$(du -sh "$CURRENT_BACKUP_DIR" | cut -f1)
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    echo "    \"backup_size\": \"$BACKUP_SIZE\"," >> "$CURRENT_BACKUP_DIR/backup_info.json"
    sed -i '$s/,$//' "$CURRENT_BACKUP_DIR/backup_info.json"
    echo "}" >> "$CURRENT_BACKUP_DIR/backup_info.json"
    
    log_success "–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ–∑–¥–∞–Ω—ã (—Ä–∞–∑–º–µ—Ä: $BACKUP_SIZE)"
}

# –°–∂–∞—Ç–∏–µ –±—ç–∫–∞–ø–∞
compress_backup() {
    log_info "–°–∂–∞—Ç–∏–µ –±—ç–∫–∞–ø–∞..."
    
    cd "$BACKUP_DIR"
    
    # –°–æ–∑–¥–∞–Ω–∏–µ tar.gz –∞—Ä—Ö–∏–≤–∞
    tar -czf "${BACKUP_NAME}.tar.gz" "$BACKUP_NAME"
    
    if [[ $? -eq 0 ]]; then
        # –£–¥–∞–ª–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ —Å–∂–∞—Ç–∏—è
        rm -rf "$BACKUP_NAME"
        
        COMPRESSED_SIZE=$(du -sh "${BACKUP_NAME}.tar.gz" | cut -f1)
        log_success "–ë—ç–∫–∞–ø —Å–∂–∞—Ç: ${BACKUP_NAME}.tar.gz ($COMPRESSED_SIZE)"
    else
        log_error "–û—à–∏–±–∫–∞ —Å–∂–∞—Ç–∏—è –±—ç–∫–∞–ø–∞"
        return 1
    fi
}

# –ó–∞–≥—Ä—É–∑–∫–∞ –≤ AWS S3
upload_to_s3() {
    if [[ -z "$S3_BUCKET" ]]; then
        log_info "S3 –±—ç–∫–∞–ø –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º..."
        return 0
    fi
    
    log_info "–ó–∞–≥—Ä—É–∑–∫–∞ –≤ AWS S3..."
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ AWS CLI
    if ! command -v aws &> /dev/null; then
        log_warning "AWS CLI –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º..."
        
        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ AWS CLI
        curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
        unzip awscliv2.zip
        ./aws/install
        rm -rf awscliv2.zip aws
    fi
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
    aws s3 cp "$BACKUP_DIR/${BACKUP_NAME}.tar.gz" \
        "s3://$S3_BUCKET/smart-trading-bot/backups/${BACKUP_NAME}.tar.gz" \
        --region "$AWS_REGION"
    
    if [[ $? -eq 0 ]]; then
        log_success "–ë—ç–∫–∞–ø –∑–∞–≥—Ä—É–∂–µ–Ω –≤ S3"
        
        # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —É–¥–∞–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ S3
        if [[ "${DELETE_LOCAL_AFTER_S3:-false}" == "true" ]]; then
            rm "$BACKUP_DIR/${BACKUP_NAME}.tar.gz"
            log_info "–õ–æ–∫–∞–ª—å–Ω—ã–π –±—ç–∫–∞–ø —É–¥–∞–ª–µ–Ω –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ S3"
        fi
    else
        log_error "–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ S3"
        return 1
    fi
}

# –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤
cleanup_old_backups() {
    log_info "–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤..."
    
    cd "$BACKUP_DIR"
    
    # –ü–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –±—ç–∫–∞–ø–æ–≤
    BACKUP_COUNT=$(ls -1 backup_*.tar.gz 2>/dev/null | wc -l)
    
    if [[ $BACKUP_COUNT -gt $MAX_BACKUPS ]]; then
        EXCESS_COUNT=$((BACKUP_COUNT - MAX_BACKUPS))
        
        # –£–¥–∞–ª–µ–Ω–∏–µ —Å–∞–º—ã—Ö —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤
        ls -1t backup_*.tar.gz | tail -n $EXCESS_COUNT | while read backup; do
            log_info "–£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π –±—ç–∫–∞–ø: $backup"
            rm "$backup"
        done
        
        log_success "–£–¥–∞–ª–µ–Ω–æ $EXCESS_COUNT —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤"
    else
        log_info "–°—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –Ω–µ—Ç ($BACKUP_COUNT/$MAX_BACKUPS)"
    fi
    
    # –û—á–∏—Å—Ç–∫–∞ S3 (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
    if [[ -n "$S3_BUCKET" ]] && command -v aws &> /dev/null; then
        log_info "–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤ –≤ S3..."
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –±—ç–∫–∞–ø–æ–≤ –≤ S3
        aws s3 ls "s3://$S3_BUCKET/smart-trading-bot/backups/" \
            --region "$AWS_REGION" \
            | sort -k1,1 -k2,2 \
            | head -n -$MAX_BACKUPS \
            | awk '{print $4}' \
            | while read file; do
                if [[ -n "$file" ]]; then
                    aws s3 rm "s3://$S3_BUCKET/smart-trading-bot/backups/$file" --region "$AWS_REGION"
                    log_info "–£–¥–∞–ª–µ–Ω –∏–∑ S3: $file"
                fi
            done
    fi
}

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –±—ç–∫–∞–ø–∞
verify_backup() {
    log_info "–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –±—ç–∫–∞–ø–∞..."
    
    BACKUP_FILE="$BACKUP_DIR/${BACKUP_NAME}.tar.gz"
    
    if [[ ! -f "$BACKUP_FILE" ]]; then
        log_error "–§–∞–π–ª –±—ç–∫–∞–ø–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: $BACKUP_FILE"
        return 1
    fi
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—Ä—Ö–∏–≤–∞
    if tar -tzf "$BACKUP_FILE" > /dev/null 2>&1; then
        log_success "–ê—Ä—Ö–∏–≤ –±—ç–∫–∞–ø–∞ –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω"
    else
        log_error "–ê—Ä—Ö–∏–≤ –±—ç–∫–∞–ø–∞ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω"
        return 1
    fi
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
    FILE_SIZE=$(stat -c%s "$BACKUP_FILE")
    if [[ $FILE_SIZE -lt 1000 ]]; then
        log_error "–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –º–∞–ª–µ–Ω—å–∫–∏–π —Ä–∞–∑–º–µ—Ä –±—ç–∫–∞–ø–∞: $FILE_SIZE –±–∞–π—Ç"
        return 1
    fi
    
    log_success "–ë—ç–∫–∞–ø –ø—Ä–æ—à–µ–ª –ø—Ä–æ–≤–µ—Ä–∫—É —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏"
}

# –û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç—á–µ—Ç–∞
send_backup_report() {
    local status="$1"
    local details="$2"
    
    BACKUP_FILE="$BACKUP_DIR/${BACKUP_NAME}.tar.gz"
    BACKUP_SIZE=""
    
    if [[ -f "$BACKUP_FILE" ]]; then
        BACKUP_SIZE=$(du -sh "$BACKUP_FILE" | cut -f1)
    fi
    
    if [[ "$status" == "success" ]]; then
        MESSAGE="‚úÖ <b>–ë—ç–∫–∞–ø –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ</b>

üìÖ <b>–î–∞—Ç–∞:</b> $(date)
üì¶ <b>–ò–º—è:</b> $BACKUP_NAME
üíæ <b>–†–∞–∑–º–µ—Ä:</b> $BACKUP_SIZE
üè† <b>–°–µ—Ä–≤–µ—Ä:</b> $(hostname)

<b>–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:</b>
‚Ä¢ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö PostgreSQL ‚úÖ
‚Ä¢ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö Redis ‚úÖ  
‚Ä¢ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Ñ–∞–π–ª—ã ‚úÖ
‚Ä¢ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ‚úÖ
‚Ä¢ –õ–æ–≥–∏ ‚úÖ

$details"
    else
        MESSAGE="‚ùå <b>–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞</b>

üìÖ <b>–î–∞—Ç–∞:</b> $(date)
üè† <b>–°–µ—Ä–≤–µ—Ä:</b> $(hostname)
‚ùå <b>–û—à–∏–±–∫–∞:</b> $details

–¢—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º—ã!"
    fi
    
    send_telegram_notification "$MESSAGE"
}

# –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ –±—ç–∫–∞–ø–∞
restore_backup() {
    local backup_file="$1"
    
    if [[ -z "$backup_file" ]]; then
        echo "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: $0 restore <backup_file.tar.gz>"
        exit 1
    fi
    
    if [[ ! -f "$backup_file" ]]; then
        log_error "–§–∞–π–ª –±—ç–∫–∞–ø–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: $backup_file"
        exit 1
    fi
    
    log_info "–ù–∞—á–∏–Ω–∞–µ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ –±—ç–∫–∞–ø–∞: $backup_file"
    
    # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
    read -p "‚ö†Ô∏è  –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–∑–∞–ø–∏—à–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ. –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? [y/N]: " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        log_info "–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ"
        exit 0
    fi
    
    # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–µ—Ä–≤–∏—Å–æ–≤
    log_info "–û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–µ—Ä–≤–∏—Å–æ–≤..."
    cd "$PROJECT_DIR"
    docker-compose down
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ —Ç–µ–∫—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    log_info "–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ —Ç–µ–∫—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö..."
    RESTORE_BACKUP_NAME="pre_restore_$(date +%Y%m%d_%H%M%S)"
    mkdir -p "$BACKUP_DIR/$RESTORE_BACKUP_NAME"
    
    if [[ -d "$PROJECT_DIR/data" ]]; then
        cp -r "$PROJECT_DIR/data" "$BACKUP_DIR/$RESTORE_BACKUP_NAME/"
    fi
    
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±—ç–∫–∞–ø–∞
    log_info "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±—ç–∫–∞–ø–∞..."
    TEMP_RESTORE_DIR="/tmp/restore_$(date +%s)"
    mkdir -p "$TEMP_RESTORE_DIR"
    
    tar -xzf "$backup_file" -C "$TEMP_RESTORE_DIR"
    EXTRACTED_DIR=$(ls -1 "$TEMP_RESTORE_DIR" | head -1)
    RESTORE_SOURCE="$TEMP_RESTORE_DIR/$EXTRACTED_DIR"
    
    # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
    log_info "–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤..."
    if [[ -d "$RESTORE_SOURCE/files/data" ]]; then
        rm -rf "$PROJECT_DIR/data"
        cp -r "$RESTORE_SOURCE/files/data" "$PROJECT_DIR/"
        log_success "–§–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã"
    fi
    
    # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    if [[ -f "$RESTORE_SOURCE/config/.env" ]]; then
        cp "$RESTORE_SOURCE/config/.env" "$PROJECT_DIR/"
        log_success "–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞"
    fi
    
    # –ó–∞–ø—É—Å–∫ PostgreSQL –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ë–î
    log_info "–ó–∞–ø—É—Å–∫ PostgreSQL..."
    docker-compose up -d postgres
    sleep 10
    
    # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    if [[ -f "$RESTORE_SOURCE/database/postgresql_full.sql.gz" ]]; then
        log_info "–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ PostgreSQL..."
        
        # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        docker-compose exec -T postgres psql -U postgres -c "DROP DATABASE IF EXISTS trading_bot;"
        docker-compose exec -T postgres psql -U postgres -c "CREATE DATABASE trading_bot;"
        
        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        gunzip -c "$RESTORE_SOURCE/database/postgresql_full.sql.gz" | \
            docker-compose exec -T postgres psql -U postgres -d trading_bot
        
        log_success "PostgreSQL –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"
    fi
    
    # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ Redis
    if [[ -f "$RESTORE_SOURCE/database/redis_dump.rdb.gz" ]]; then
        log_info "–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ Redis..."
        
        docker-compose stop redis
        
        # –ù–∞–π—Ç–∏ —Ç–æ–º Redis
        REDIS_VOLUME=$(docker volume ls | grep redis_data | awk '{print $2}' | head -1)
        if [[ -n "$REDIS_VOLUME" ]]; then
            REDIS_PATH="/var/lib/docker/volumes/${REDIS_VOLUME}/_data"
            gunzip -c "$RESTORE_SOURCE/database/redis_dump.rdb.gz" > "$REDIS_PATH/dump.rdb"
            log_success "Redis –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"
        fi
    fi
    
    # –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
    log_info "–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤..."
    docker-compose up -d
    
    # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    rm -rf "$TEMP_RESTORE_DIR"
    
    log_success "–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!"
    log_info "–†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö: $BACKUP_DIR/$RESTORE_BACKUP_NAME"
}

# –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
main() {
    case "${1:-backup}" in
        "backup")
            log_info "üöÄ –ù–∞—á–∏–Ω–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞..."
            
            start_time=$(date +%s)
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –Ω–∞—á–∞–ª–µ
            send_telegram_notification "üîÑ <b>–ù–∞—á–∞—Ç–æ —Å–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞</b>

üìÖ $(date)
üè† $(hostname)
üì¶ $BACKUP_NAME"
            
            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –±—ç–∫–∞–ø–∞
            if check_dependencies && \
               create_backup_directories && \
               backup_database && \
               backup_files && \
               backup_logs && \
               create_backup_metadata && \
               compress_backup && \
               verify_backup; then
                
                # –ó–∞–≥—Ä—É–∑–∫–∞ –≤ S3 (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                upload_to_s3 || log_warning "–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ S3, –Ω–æ –±—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω –ª–æ–∫–∞–ª—å–Ω–æ"
                
                # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤
                cleanup_old_backups
                
                end_time=$(date +%s)
                duration=$((end_time - start_time))
                
                send_backup_report "success" "‚è±Ô∏è <b>–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:</b> ${duration}—Å"
                log_success "‚úÖ –ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ –∑–∞ ${duration} —Å–µ–∫—É–Ω–¥"
                
            else
                send_backup_report "error" "–û—à–∏–±–∫–∞ –Ω–∞ –æ–¥–Ω–æ–º –∏–∑ —ç—Ç–∞–ø–æ–≤ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞"
                log_error "‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞"
                exit 1
            fi
            ;;
            
        "restore")
            restore_backup "$2"
            ;;
            
        "list")
            log_info "üìã –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –±—ç–∫–∞–ø–æ–≤:"
            if [[ -d "$BACKUP_DIR" ]]; then
                ls -lah "$BACKUP_DIR"/*.tar.gz 2>/dev/null || echo "–ë—ç–∫–∞–ø—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
            else
                echo "–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –±—ç–∫–∞–ø–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
            fi
            ;;
            
        "cleanup")
            log_info "üßπ –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤..."
            cleanup_old_backups
            ;;
            
        "verify")
            if [[ -n "$2" ]]; then
                log_info "üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –±—ç–∫–∞–ø–∞: $2"
                BACKUP_NAME=$(basename "$2" .tar.gz)
                verify_backup
            else
                echo "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: $0 verify <backup_file.tar.gz>"
                exit 1
            fi
            ;;
            
        *)
            echo "Smart Trading Bot - Backup Script"
            echo ""
            echo "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: $0 {backup|restore|list|cleanup|verify}"
            echo ""
            echo "–ö–æ–º–∞–Ω–¥—ã:"
            echo "  backup            - –°–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—ã–π –±—ç–∫–∞–ø"
            echo "  restore <file>    - –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏–∑ –±—ç–∫–∞–ø–∞"
            echo "  list             - –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –±—ç–∫–∞–ø–æ–≤"
            echo "  cleanup          - –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã"
            echo "  verify <file>    - –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –±—ç–∫–∞–ø–∞"
            echo ""
            echo "–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:"
            echo "  S3_BACKUP_BUCKET          - Bucket –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ S3"
            echo "  DELETE_LOCAL_AFTER_S3     - –£–¥–∞–ª—è—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –ø–æ—Å–ª–µ S3"
            echo "  BACKUP_NOTIFICATION_BOT_TOKEN - –¢–æ–∫–µ–Ω –±–æ—Ç–∞ –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π"
            echo "  BACKUP_NOTIFICATION_CHAT_ID   - Chat ID –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π"
            exit 1
            ;;
    esac
}

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–≥–Ω–∞–ª–æ–≤
trap 'log_error "–°–∫—Ä–∏–ø—Ç –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º"; exit 1' INT TERM

# –ó–∞–ø—É—Å–∫
main "$@"